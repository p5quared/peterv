---
title: "Academic Integrity"
date: 2023-12-22
description: "What does it mean to have academic integrity? And why I think schools have it wrong."
tags: ["school", "rant", "essay"]
---

According to *Cassell's Latin Dictionary*, "**college**" is from the Latin *lego, legere, legi, lectum,* literally "to collect, gather, [or] pick", and *cum*, which of course is "with". In other words, the word is roughly equivalent to *selected together* (this also is a broader version of colleagues i.e. people chosen to *work* together). This doesn't really tell us much.

From *Oxford Languages:*

> an educational institution or establishment, in particular one providing higher education or specialized professional or vocational training.

Okay, so colleges are places which are designed to teach specific things, which sounds good. People like to hear that you went to college. So why don't you just lie about having gone to college? Well, you say, you are given a degree when you graduate, which signifies that you have learned some material to some standard.

And *that* is the invincible core of our modern education system! Or, once invincible*.* Unless you've been living under a rock (like I do) there is no way you have not been witnessing the rising prevalence of artificial intelligence, and one of the very visibly affected regions of life is education. With tools like ChatGPT, students can write an essay about "To Kill a Mockingbird" faster than you can say "one in the hand is worth two in the bush". Well actually, the problem is they aren't writing it, an AI is. It should be glaringly obvious that by having an AI do your work for you, you have to put in a fraction of the effort and a fraction of the *thought.* While it is technically speculation, I don't think many would disagree that students who use these tools in place of actual effort and thought are going to turn out utterly underdeveloped, particularly with regard to their ability to think creatively and critically. 

Wait a minute... So what if someone goes to college, and submits work that an AI produced, and graduates? If they didn't have to learn or think about the work they submitted then they probably haven't reached the subject mastery expected for a degree! It is roughly the equivalent of paying someone to do your homework for you! In fact, if you are a college and too many students do this **and** get degrees, people might start to question the development of *all* the students from this college... **What should colleges do to mitigate this risk?**

Well, luckily we have a case study: The University at Buffalo (SUNY). Rumor (a friend and alum) has told me that not long ago, this very thing (highly decreased degree value) happened to the computer science department. That is, so many graduates had no clue what they were doing in their jobs, that employers noticed a pattern and decided to stop hiring from the school. The situation is so incredibly bad that I find it hilarious. 

Anyways, what has the school since done to 'fix' the problem? Well, among other things, they have implemented strict policies on (the ironically named) AI (academic integrity). Some of them are pretty mundane and what should be completely obvious already: i.e. "Purchasing an academic assignment intended for submission in fulfillment of any course or academic program requirement." But there are a few strategies I have seen that I think are completely working against what should be universal goals in higher education.

Let me show you what I'm talking about:

> As the Allowable Resources section describes, the *only* allowable resources are those which are explicitly allowed by the course syllabus or individual assignment handouts.

*Okay, *you say,* so you're limited to learning from the textbook and maybe a handful of extra sources you're given, what's wrong with that?* ***WHAT'S WRONG WITH THAT?*** It should be obvious what is wrong with the statement in that policy. The policy is outlawing the entire wealth of humanity's knowledge, except for the tiniest sliver which is chosen by an instructor. Why is that a bad thing? Ask yourself, if two students finish the same course and one is allowed to use *any* source, and one is only allowed to use *one or two* sources, which student do you think is more knowledgeable on the subject at the end? Obviously, if someone can learn the same material from any sources they please, they will not only have an easier time learning (because they can find a source whose style suits them better), but they can also build a more rock-solid understanding of material by seeing how it is presented by different authors.

*Wait a minute,* you say,* but your comparison is wrong; what if the student with every source cheats?* Then the student who was too afraid of some educator to cheat learns more right? Yes, that is true but my stance is that cheating is cheating yourself. Even with the strict AI policies, I still see at least half a dozen students deep in ChatGPT every lecture. Why attempt to punish (what is hopefully) the majority of honest students who care about their competency for actions of those who are ultimately harming themselves already? The decision of many professors to act in this manner is not only illogical, but utterly patronizing and frankly insecure to start every semester by assuming everyone is a cheater, rather than attempt to structure courses and departments in a manner which would better handle the AI (artificial intelligence) crisis.

So, if you've read this far you can see I'm quite full of myself; what would I do instead? First, all sources are unrestricted, with the only guidelines for homework or projects being to forbid plagiarism. All homework is allowed full collaboration as well (I didn't even touch on this, but generally collaboration is completely barred at UB). All courses should be graded without a curve, and for larger classes where it is not practical to closely check for plagiarism on all work, exam weights should be such that you need to have some passing exam average to pass the course. In this model, students can *learn* the material from any source they want. They *prove* that they understand and apply the material by passing the exams. This isn't revolutionary--this is actually how many colleges have done things for hundreds of years, to great success.

By allowing for open sources, and complete collaboration, students can learn material in *their* own way and together, instead of in the way one professor considers best for *themselves.* This is a benefit for students who are passionate about their topics, and not going so easy on grading keeps out the most of the riffraff. 

Maybe you don't like my "let the kids go wild" approach, but don't take my word for it, do you think MIT is a good school? Well, look at how MIT encourages learning with its AI policies:

> The goal of homework is to give you practice in mastering the course material. Consequently, you are encouraged to collaborate on problem sets. In fact, students who form study groups generally do better on exams than do students who work alone. If you do work in a study group, however, you owe it to yourself and your group to be prepared for your study group meeting. Specifically, you should spend at least 30–45 minutes trying to solve each problem beforehand.

> You must write up each problem solution by yourself without assistance, even if you collaborate with others to solve the problem. You are asked on problem sets to identify your collaborators. If you did not work with anyone, you should write that you did not have collaborators. If you obtain a solution through research (e.g., on the web), acknowledge your source, but write up the solution in your own words. It is a violation of this policy to submit a problem solution that you cannot orally explain to a member of the course staff.

> Code you submit must also be written by yourself. You may receive help from your classmates during debugging. Don’t spend hours trying to debug a problem in your code before asking for help. However, regardless of who is helping you, only you are allowed to make changes to your code. Both manual and automatic mechanisms will be employed to detect plagiarism in code.

> No other 6.006 student may use your solutions; this includes your writing, code, tests, documentation, etc. It is a violation of the 6.006 collaboration policy to permit anyone other than 6.006 staff and yourself to see your solutions to either theory or code questions.

> Plagiarism and other anti-intellectual behavior cannot be tolerated in any academic environment that prides itself on individual accomplishment. If you have any questions about the collaboration policy, or if you feel that you may have violated the policy, please talk to one of the course staff. Although the course staff is obligated to deal with cheating appropriately, we often have the ability to be more understanding and lenient if we find out from the transgressor himself or herself rather than from a third party. [Taken from MIT 6.006F11]

Look at some of the key points:

The goal of homework is to give you practice in mastering the course material.

students who form study groups generally do better on exams than do students who work alone

You may receive help from your classmates during debugging. Don’t spend hours trying to debug a problem in your code before asking for help.

My favorite, which I think really demonstrates the pragmatism of MIT:

It is a violation of this policy to submit a problem solution that you cannot orally explain to a member of the course staff.

In other words, *it is cheating if you didn't learn anything*. MIT has it figured out: you're not supposed to be forcing every kid down the same path. It seems to be the case that at schools like UB (I doubt this is a unique case), AI is an ideal or paradigm which, in the process of developing metrics to maintain it, professors and bureaucrats have forgotten the original intention of the term. The *real* goal of AI was never to catch kids from cheating, nor was it to catch kids from learning material from the wrong place, the deeper goal was and should still be to catch kids who *aren't learning*.